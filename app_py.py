# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jZn-yNezm9bD_Hwg5j24eGvZdrEiIuGk

##README
"""

# BuySmart: Purchase Prediction App

This app predicts whether customers will make a purchase based on their demographic data.

## How to Run the App
1. Clone this repository:

2. Navigate to the project folder:

3. Install the required dependencies:

4. Run the app:


5. Open the link provided in the terminal to view the app in your browser.

## Features
- Upload customer data via CSV.
- View the uploaded data.
- Train and evaluate a Logistic Regression model.
- Predict customer behavior based on demographic inputs.

## Example Dataset
An example dataset is provided in the `Data/` folder for testing the app.

"""##Streamlit App Code"""

!pip install streamlit

import streamlit as st
import pandas as pd

st.title("BuySmart: Purchase Prediction App")
st.write("Welcome! Upload your data to predict customer purchase behavior.")

uploaded_file = st.file_uploader("Upload CSV", type=["csv"])
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("Uploaded Dataset:")
    st.dataframe(df)

print("Streamlit is installed and working!")

"""###Install Streamlit

##Import libraries
"""

import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""##Mount Drive"""

from google.colab import drive
drive.mount('/content/drive')

#!ls "/content/drive/My Drive"

file_path = '/content/drive/My Drive/Data.csv'
if os.path.exists(file_path):
      print("File exists")
else:
    print("File does not exist")

"""##Load the dataset"""

# Step 1:Load the dataset

df = pd.read_csv(file_path)
#print entire dataframe
print(df)

# Verify that 'Country' exists
print("Columns in df after loading:")
print(df.columns)

print("Columns in df:")
print(df.columns)

print("First few rows of df:")
print(df.head())

# Step 2: Impute missing values for the 'Country' column in the original df
categorical_imputer = SimpleImputer(strategy='most_frequent')
df['Country'] = categorical_imputer.fit_transform(df[['Country']]).ravel()

# Step 3: Define features (x) and target (y)
x = df.drop('Purchased', axis=1)
y = df['Purchased']

# Step 4: OneHotEncode the 'Country' column
onehot_encoder = OneHotEncoder()
countries_encoded = onehot_encoder.fit_transform(x[['Country']]).toarray()
country_df = pd.DataFrame(countries_encoded, columns=onehot_encoder.get_feature_names_out(['Country']))
x = pd.concat([x, country_df], axis=1).drop(['Country'], axis=1)

# Step 5: Impute missing values for numerical columns
numerical_imputer = SimpleImputer(strategy='mean')
x[['Age', 'Salary']] = numerical_imputer.fit_transform(x[['Age', 'Salary']])

# Step 5: Scale numerical columns
scaler = StandardScaler()
x[['Age', 'Salary']] = scaler.fit_transform(x[['Age', 'Salary']])

# Step 6: Verify preprocessing
print("Columns in x after preprocessing:")
print(x.columns)

"""###Feature Scaling"""

scaler = StandardScaler()
x[['Age', 'Salary']] = scaler.fit_transform(x[['Age', 'Salary']])

"""##Step 4: Splitting the data"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

print('Preprocessing Complete!')
print('Training features: \n', x_train.head())
print('Target values: \n', y_train.head())

"""###Initialize the model"""

model = LogisticRegression()
model.fit(x_train, y_train)

# Save the model to a file
joblib.dump(model, "logistic_model.pkl")

"""###Make predictions"""

# Load the trained model
model = joblib.load("logistic_model.pkl")

y_pred = model.predict(x_test)

"""###Evaluate the model"""

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

"""###Print Evaluation metrics"""

print(f'Model Accuracy: {accuracy * 100:.2f}%')
print('\nConfusion Matrix:\n', conf_matrix)
print('\nClassification Report:\n', class_report)

"""###Visualize the results"""

sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""###Save and document"""

x_train.to_csv('x_train.csv', index=False)
y_train.to_csv('y_train.csv', index=False)